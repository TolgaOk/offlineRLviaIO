{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -\n",
    "## Iterative IO algorithm\n",
    "- - -\n",
    "#### Quadrotor Environment\n",
    "\n",
    "The Q minimization:\n",
    "$$\n",
    "\\min_u 2s^T\\theta_{su}u + u^T\\theta_{uu}u \\\\ \\text{s.t.} \\quad G_u u \\leq h_u\n",
    "$$\n",
    "\n",
    "- Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from itertools import product\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "\n",
    "from io_agent.evaluator import Transition\n",
    "from io_agent.plant.quadrotor import QuadrotorEnv\n",
    "\n",
    "from common import run_mpc, run_io_rmpc\n",
    "from utils import parallelize, steady_state_cost, save_experiment\n",
    "\n",
    "\n",
    "n_cpu = multiprocessing.cpu_count()\n",
    "horizon = 25\n",
    "n_trials = 20\n",
    "n_past = 2\n",
    "add_bias = False\n",
    "n_dataset_trials = 20\n",
    "n_rhos = 12\n",
    "general_seed = 42\n",
    "seed_rng = np.random.default_rng(general_seed)\n",
    "\n",
    "plant = QuadrotorEnv()\n",
    "permute_seed, *trial_seeds = seed_rng.integers(0, 2**30, n_trials + 1)\n",
    "dataset_trial_seeds = seed_rng.integers(0, 2**30, n_dataset_trials)\n",
    "\n",
    "dataset_trajectories = parallelize(\n",
    "    n_proc=min(n_cpu, n_dataset_trials),\n",
    "    fn=partial(run_mpc, plant=plant),\n",
    "    kwargs_list=[\n",
    "        dict(\n",
    "            horizon=horizon,\n",
    "            use_foresight=False,  # Without hindsight data\n",
    "            bias_aware=False,\n",
    "            env_reset_rng=np.random.default_rng(_seed)\n",
    "        ) for _seed in dataset_trial_seeds\n",
    "    ],\n",
    "    loading_bar_kwargs=dict(desc=\"MPC dataset trials\")\n",
    ")\n",
    "\n",
    "save_experiment(\n",
    "    values={\"mpc_dataset\": dataset_trajectories},\n",
    "    seed=general_seed,\n",
    "    exp_dir=\"./quadrotor_data/dataset\",\n",
    "    name=\"mpc_obl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Construct the Q function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, List, Tuple, Optional, Any, Union, Dict\n",
    "from dataclasses import dataclass\n",
    "from functools import partial\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import geotorch\n",
    "import cvxpy as cp\n",
    "\n",
    "from io_agent.plant.quadrotor import QuadrotorEnv\n",
    "from io_agent.plant.base import (NominalLinearEnvParams,\n",
    "                                 LinearizationWrapper,\n",
    "                                 LinearConstraints,\n",
    "                                 LinearConstraint,\n",
    "                                 Plant)\n",
    "from io_agent.control.mpc import Optimizer\n",
    "from io_agent.utils import AugmentedTransition, FeatureHandler\n",
    "from io_agent.control.io import AugmentDataset\n",
    "from io_agent.control.mpc import MPC\n",
    "from io_agent.control.deep_io import IterativeIOController\n",
    "from io_agent.evaluator import Transition\n",
    "\n",
    "from utils import load_experiment, parallelize\n",
    "from common import run_agent\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DeepIOArgs():\n",
    "    n_past: int = 2\n",
    "    add_bias: int = False\n",
    "    use_action_regressor: bool = False\n",
    "    use_noise_regressor: bool = True\n",
    "    use_state_regressor: bool = False\n",
    "    horizon: int = 25\n",
    "    use_expert: bool = False\n",
    "    learning_rate: float = 1e-2\n",
    "    lr_exp_decay: float = 0.98\n",
    "    n_epoch: int = 1000\n",
    "    n_batch: int = 128\n",
    "\n",
    "\n",
    "def prepare_deep_io(dataset: List[List[Transition]],\n",
    "                  env: Plant,\n",
    "                  rng: np.random.Generator,\n",
    "                  args: DeepIOArgs,\n",
    "                  verbose: bool = True\n",
    "                  ) -> IterativeIOController:\n",
    "    feature_handler = FeatureHandler(\n",
    "        params=env.nominal_model(),\n",
    "        n_past=args.n_past,\n",
    "        add_bias=args.add_bias,\n",
    "        use_action_regressor=args.use_action_regressor,\n",
    "        use_noise_regressor=args.use_noise_regressor,\n",
    "        use_state_regressor=args.use_state_regressor,\n",
    "    )\n",
    "    expert_agent = None\n",
    "    if args.use_expert:\n",
    "        expert_agent = MPC(\n",
    "            action_size=lin_env.action_size,\n",
    "            state_size=lin_env.state_size,\n",
    "            noise_size=lin_env.noise_size,\n",
    "            output_size=lin_env.output_size,\n",
    "            horizon=args.horizon)\n",
    "        expert_agent.optimizer = expert_agent.prepare_optimizer(feature_handler.params)\n",
    "    augmenter = AugmentDataset(\n",
    "        expert_agent=expert_agent,\n",
    "        feature_handler=feature_handler,\n",
    "    )\n",
    "    augmented_dataset = augmenter(dataset)\n",
    "    torch.manual_seed(rng.integers(0, 2**30).item())\n",
    "    iterative_io_agent = IterativeIOController(\n",
    "        constraints=feature_handler.params.constraints,\n",
    "        feature_handler=feature_handler,\n",
    "        learning_rate=args.learning_rate,\n",
    "        include_constraints=True,\n",
    "        action_constraints_flag=True,\n",
    "        state_constraints_flag=False,\n",
    "        lr_exp_decay=args.lr_exp_decay,\n",
    "    )\n",
    "    return iterative_io_agent, augmented_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "from common import run_agent\n",
    "from utils import save_experiment\n",
    "\n",
    "\n",
    "lin_env = LinearizationWrapper(QuadrotorEnv())\n",
    "dataset = load_experiment(\"./quadrotor_data/dataset/mpc_obl-42\")[\"mpc_dataset\"]\n",
    "\n",
    "n_trials = 50\n",
    "n_cpu = multiprocessing.cpu_count()\n",
    "general_seed = 43\n",
    "seed_rng = np.random.default_rng(general_seed)\n",
    "trial_seeds = seed_rng.integers(0, 2**30, n_trials)\n",
    "evaluation_epochs = [int(val) for val in np.floor(np.logspace(1, 3, 15))]\n",
    "\n",
    "\n",
    "def deep_io_trials(args: DeepIOArgs, rng: np.random.Generator, trial_seeds: List[int]):\n",
    "    if args.n_epoch != 0:\n",
    "        raise ValueError(\"```n_epoch``` must be set to 0\")\n",
    "    deep_io_agent, augmented_dataset = prepare_deep_io(\n",
    "        dataset, lin_env, rng, args, verbose=False)\n",
    "    losses = []\n",
    "    costs = {}\n",
    "    with tqdm(total=evaluation_epochs[-1]) as pbar:\n",
    "        for eval_break_epoch in evaluation_epochs:\n",
    "            n_epoch = eval_break_epoch - len(losses)\n",
    "            _losses = deep_io_agent.train(\n",
    "                augmented_dataset,\n",
    "                epochs=n_epoch,\n",
    "                batch_size=args.n_batch,\n",
    "                rng=rng,\n",
    "                verbose=False)\n",
    "            losses.extend(_losses)\n",
    "            deep_io_agent.action_optimizer = deep_io_agent.prepare_action_optimizer()\n",
    "            deep_io_trajectories = parallelize(\n",
    "                n_proc=min(n_cpu, 50),\n",
    "                fn=partial(run_agent, agent=deep_io_agent, plant=lin_env),\n",
    "                kwargs_list=[\n",
    "                    dict(\n",
    "                        use_foresight=False,\n",
    "                        bias_aware=False,\n",
    "                        env_reset_rng=np.random.default_rng(_seed)\n",
    "                    ) for _seed in trial_seeds\n",
    "                ],\n",
    "            )\n",
    "            deep_io_costs = [300 - np.sum([np.exp(-tran.cost) for tran in trajectory])\n",
    "                             for trajectory in deep_io_trajectories]\n",
    "            costs[eval_break_epoch] = deep_io_costs\n",
    "            pbar.set_postfix({\"Median cost\": np.median(deep_io_costs)})\n",
    "            pbar.update(n_epoch)\n",
    "    return costs, losses\n",
    "\n",
    "\n",
    "experiment_args = {\n",
    "    \"DeepIO-No-expert\": DeepIOArgs(use_expert=False, n_epoch=0),\n",
    "    \"DeepIO-MPC-expert\": DeepIOArgs(use_expert=True, n_epoch=0),\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for key, args in experiment_args.items():\n",
    "    results[key] = deep_io_trials(\n",
    "        args,\n",
    "        np.random.default_rng(seed_rng.integers(0, 2*30)),\n",
    "        trial_seeds)\n",
    "    \n",
    "\n",
    "save_experiment(\n",
    "    values={\"deep-io\": results},\n",
    "    seed=general_seed,\n",
    "    exp_dir=\"./quadrotor_data/ablation\",\n",
    "    name=\"deep-io\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.ticker as tck\n",
    "\n",
    "from utils import steady_state_cost, load_experiment\n",
    "from collections import defaultdict\n",
    "from plotter import histogram_figure, histogram_figure_plt, tube_figure_plt\n",
    "\n",
    "\n",
    "fig = histogram_figure_plt(\n",
    "    cost_data={key: value[0][1000] for key, value in results.items()},\n",
    "    title=\"\",\n",
    "    bw_method=\"scott\",\n",
    "    bw_adjust=0.30,\n",
    "    log_yaxis=True,\n",
    "    y_label=\"log density\",\n",
    "    low_y=1e-3,\n",
    "    figsize=(6, 3)\n",
    ")\n",
    "\n",
    "fig, axes = tube_figure_plt(\n",
    "    cost_data={key: value[0] for key, value in results.items()},\n",
    "    title=f\"\",\n",
    "    log_xaxis=True,\n",
    "    log_yaxis=False,\n",
    "    x_label=\"epoch\",\n",
    "    y_label=\"episodic cost\",\n",
    "    percentiles=(20, 80)\n",
    ")\n",
    "\n",
    "fig, axes = tube_figure_plt(\n",
    "    cost_data={key: {index + 1: value for index, value in enumerate(value[1])} for key, value in results.items()},\n",
    "    title=f\"\",\n",
    "    log_xaxis=True,\n",
    "    log_yaxis=True,\n",
    "    x_label=\"epoch\",\n",
    "    y_label=\"sub loss\",\n",
    "    percentiles=(20, 80)\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
