{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quadrotor Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use one of the [safe-control-gym](https://github.com/utiasDSL/safe-control-gym) environment.\n",
    "> Please make sure that you have installed necessary packages to run the following cells.\n",
    "\n",
    "### MPC and RL agent comparison\n",
    "\n",
    "- Train PPO agent\n",
    "- MPC Ablation on horizon and hindsight\n",
    "- Compare RL agent and MPC variants\n",
    "> Note that, we use [stable baselines 3](https://stable-baselines3.readthedocs.io/en/master/) repository as the source of RL agent implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from functools import partial\n",
    "import os\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "\n",
    "from io_agent.plant.quadrotor import QuadrotorEnv\n",
    "from io_agent.control.ppo import PPoController\n",
    "from io_agent.evaluator import ControlLoop\n",
    "from io_agent.plant.base import Plant\n",
    "from io_agent.runner.basic import run_mpc\n",
    "from io_agent.utils import parallelize, save_experiment\n",
    "\n",
    "\n",
    "n_cpu = multiprocessing.cpu_count()\n",
    "n_trials = 20\n",
    "mpc_horizons = [15, 20, 25, 30, 35, 40]\n",
    "general_seed = 42\n",
    "seed_rng = np.random.default_rng(general_seed)\n",
    "\n",
    "plant = QuadrotorEnv()\n",
    "trial_seeds = seed_rng.integers(0, 2**30, n_trials)\n",
    "\n",
    "ppo_path = f\"./quadrotor_data/ppo-1m-{general_seed}\"\n",
    "if not os.path.exists(\".\".join([ppo_path, \"zip\"])):\n",
    "    PPoController.train(lambda: QuadrotorEnv(use_exp_reward=True),\n",
    "                        n_envs=10,\n",
    "                        seed=general_seed,\n",
    "                        path=ppo_path,\n",
    "                        total_timesteps=int(1e6))\n",
    "ppo_agent = PPoController(ppo_path)\n",
    "\n",
    "ablation_keys = list(product(mpc_horizons, [True, False]))\n",
    "\n",
    "\n",
    "def run_mpc_experiment(plant: Plant, horizon: int, use_hindsight: bool):\n",
    "    return parallelize(\n",
    "        n_proc=min(n_cpu, n_trials),\n",
    "        fn=partial(run_mpc, plant=plant),\n",
    "        kwargs_list=[\n",
    "            dict(\n",
    "                horizon=horizon,\n",
    "                use_foresight=use_hindsight,\n",
    "                bias_aware=False,\n",
    "                env_reset_rng=np.random.default_rng(_seed)\n",
    "            ) for _seed in trial_seeds\n",
    "        ],\n",
    "        loading_bar_kwargs=dict(desc=f\"MPC with horizon:{horizon} and hindsight: {use_hindsight}\")\n",
    "    )\n",
    "\n",
    "\n",
    "def evaluate_ppo(seed: int):\n",
    "    return ControlLoop(plant=plant,\n",
    "                       controller=ppo_agent,\n",
    "                       rng=np.random.default_rng(seed)\n",
    "                       ).simulate(False, False)\n",
    "\n",
    "\n",
    "mpc_ablation_trajectories = parallelize(\n",
    "    n_proc=n_cpu // min(n_cpu, n_trials),\n",
    "    fn=partial(run_mpc_experiment, plant=plant),\n",
    "    kwargs_list=[dict(horizon=horizon, use_hindsight=hindsight)\n",
    "                 for horizon, hindsight in ablation_keys],\n",
    "    loading_bar_kwargs=dict(desc=f\"MPC ablation study\")\n",
    ")\n",
    "\n",
    "ppo_trajectories = [\n",
    "    evaluate_ppo(seed=_seed)\n",
    "    for _seed in tqdm(trial_seeds, desc=f\"PPO agent evaluation\")\n",
    "]\n",
    "\n",
    "# Save the experiment since it takes some time to complete.\n",
    "save_experiment(\n",
    "    values={\n",
    "        \"mpc_ablation_trajectories\": {\n",
    "            key: trajectories for key, trajectories in zip(ablation_keys, mpc_ablation_trajectories)},\n",
    "        \"ppo_trajectories\": ppo_trajectories\n",
    "    },\n",
    "    seed=general_seed,\n",
    "    exp_dir=\"./quadrotor_data/ablation\",\n",
    "    name=\"mpc_vs_ppo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io_agent.utils import steady_state_cost, load_experiment\n",
    "from io_agent.plotter import tube_figure\n",
    "\n",
    "exp_trajectories = load_experiment(\"./quadrotor_data/ablation/mpc_vs_ppo-42\")\n",
    "mpc_trajectories = exp_trajectories[\"mpc_ablation_trajectories\"]\n",
    "ppo_trajectories = exp_trajectories[\"ppo_trajectories\"]\n",
    "\n",
    "tube_figure(\n",
    "    cost_data={\n",
    "        \"MPC (w/ Hindsight)\": {key[0]: steady_state_cost(traj, 0.4)\n",
    "                               for key, traj in mpc_trajectories.items() if key[1] == True},\n",
    "        \"MPC (w/o Hindsight)\": {key[0]: steady_state_cost(traj, 0.4)\n",
    "                                for key, traj in mpc_trajectories.items() if key[1] == False},\n",
    "        \"PPO\": {key[0]: (steady_state_cost(ppo_trajectories, 0.4))\n",
    "                for key in mpc_trajectories.keys()}\n",
    "    },\n",
    "    title=f\"Quadrotor 2D - Expert Performance Comparison\",\n",
    "    log_xaxis=False,\n",
    "    log_yaxis=True,\n",
    "    xaxis_name=\"MPC horizon\",\n",
    "    percentiles=(20, 80)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- IO-MPC lookback horizon ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from functools import partial\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "\n",
    "from io_agent.evaluator import Transition\n",
    "from io_agent.plant.quadrotor import QuadrotorEnv\n",
    "from io_agent.runner.basic import run_mpc, run_io_mpc\n",
    "from io_agent.utils import parallelize, save_experiment\n",
    "\n",
    "\n",
    "n_cpu = multiprocessing.cpu_count()\n",
    "horizon = 25\n",
    "n_trials = n_cpu // 4\n",
    "n_dataset_trials = 20\n",
    "general_seed = 42\n",
    "lookbacks = [0, 2, 4, 8, 12, 16]\n",
    "seed_rng = np.random.default_rng(general_seed)\n",
    "\n",
    "plant = QuadrotorEnv()\n",
    "permute_seed, *trial_seeds = seed_rng.integers(0, 2**30, n_trials + 1)\n",
    "dataset_trial_seeds = seed_rng.integers(0, 2**30, n_dataset_trials)\n",
    "\n",
    "dataset_trajectories = parallelize(\n",
    "    n_proc=min(n_cpu, n_dataset_trials),\n",
    "    fn=partial(run_mpc, plant=plant),\n",
    "    kwargs_list=[\n",
    "        dict(\n",
    "            horizon=horizon,\n",
    "            use_foresight=False,  # Without hindsight data\n",
    "            bias_aware=False,\n",
    "            env_reset_rng=np.random.default_rng(_seed)\n",
    "        ) for _seed in dataset_trial_seeds\n",
    "    ],\n",
    "    loading_bar_kwargs=dict(desc=\"MPC dataset trials\")\n",
    ")\n",
    "\n",
    "\n",
    "def lookback_horizon_experiment(n_past: int) -> List[List[Transition]]:\n",
    "    return parallelize(\n",
    "        n_proc=min(n_trials, n_cpu),\n",
    "        fn=run_io_mpc(dataset_trajectories,\n",
    "                      dataset_length=300,\n",
    "                      n_past=n_past,\n",
    "                      add_bias=False,\n",
    "                      expert_horizon=horizon,\n",
    "                      plant=plant,\n",
    "                      dataset_permute_rng=np.random.default_rng(permute_seed)),\n",
    "        kwargs_list=[\n",
    "            dict(env_reset_rng=np.random.default_rng(_seed))\n",
    "            for _seed in trial_seeds\n",
    "        ],\n",
    "        loading_bar_kwargs=dict(desc=f\"IO-MPC, H:{n_past}\")\n",
    "    )\n",
    "\n",
    "\n",
    "ablation_trajectories = parallelize(\n",
    "    n_proc=n_cpu // min(n_trials, n_cpu),\n",
    "    fn=lookback_horizon_experiment,\n",
    "    kwargs_list=[dict(n_past=n_past) for n_past in lookbacks],\n",
    "    loading_bar_kwargs=dict(desc=\"IO-MPC H-ablation\")\n",
    ")\n",
    "\n",
    "# Save the experiment since it takes some time to complete.\n",
    "save_experiment(\n",
    "    values={\"h_ablation\": {\n",
    "        key: trajectories for key,\n",
    "        trajectories in zip(lookbacks, ablation_trajectories)}},\n",
    "    seed=general_seed,\n",
    "    exp_dir=\"./quadrotor_data/ablation\",\n",
    "    name=\"io_mpc_lookbacks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io_agent.utils import steady_state_cost, load_experiment\n",
    "from io_agent.plotter import tube_figure\n",
    "\n",
    "exp_trajectories = load_experiment(\"./quadrotor_data/ablation/io_mpc_lookbacks-42\")\n",
    "io_mpc_trajectories = exp_trajectories[\"h_ablation\"]\n",
    "exp_trajectories = load_experiment(\"./quadrotor_data/ablation/mpc_vs_ppo-42\")\n",
    "mpc_trajectories = exp_trajectories[\"mpc_ablation_trajectories\"]\n",
    "\n",
    "tube_figure(\n",
    "    cost_data={\n",
    "        \"IO-MPC (25)\": {key: steady_state_cost(traj, 0.4)\n",
    "                        for key, traj in io_mpc_trajectories.items()},\n",
    "        \"MPC (25, w/ Hindsight)\": {key: steady_state_cost(mpc_trajectories[(25, True)], 0.4)\n",
    "                               for key in io_mpc_trajectories.keys()},\n",
    "        \"MPC (25, w/o Hindsight)\": {key: steady_state_cost(mpc_trajectories[(25, False)], 0.4)\n",
    "                                for key in io_mpc_trajectories.keys()},\n",
    "    },\n",
    "    title=f\"Quadrotor 2D - Controller Memory Ablation\",\n",
    "    log_xaxis=False,\n",
    "    log_yaxis=False,\n",
    "    xaxis_name=\"lookback horizon\",\n",
    "    percentiles=(40, 60)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- IO-RMPC $\\rho$ Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from itertools import product\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "\n",
    "from io_agent.evaluator import Transition\n",
    "from io_agent.plant.quadrotor import QuadrotorEnv\n",
    "from io_agent.runner.basic import run_mpc, run_io_rmpc\n",
    "from io_agent.utils import parallelize, save_experiment\n",
    "\n",
    "\n",
    "n_cpu = multiprocessing.cpu_count()\n",
    "horizon = 25\n",
    "n_trials = 20\n",
    "n_past = 2\n",
    "add_bias = False\n",
    "n_dataset_trials = 20\n",
    "n_rhos = 12\n",
    "general_seed = 42\n",
    "seed_rng = np.random.default_rng(general_seed)\n",
    "\n",
    "plant = QuadrotorEnv()\n",
    "permute_seed, *trial_seeds = seed_rng.integers(0, 2**30, n_trials + 1)\n",
    "dataset_trial_seeds = seed_rng.integers(0, 2**30, n_dataset_trials)\n",
    "\n",
    "dataset_trajectories = parallelize(\n",
    "    n_proc=min(n_cpu, n_dataset_trials),\n",
    "    fn=partial(run_mpc, plant=plant),\n",
    "    kwargs_list=[\n",
    "        dict(\n",
    "            horizon=horizon,\n",
    "            use_foresight=False,  # Without hindsight data\n",
    "            bias_aware=False,\n",
    "            env_reset_rng=np.random.default_rng(_seed)\n",
    "        ) for _seed in dataset_trial_seeds\n",
    "    ],\n",
    "    loading_bar_kwargs=dict(desc=\"MPC dataset trials\")\n",
    ")\n",
    "\n",
    "\n",
    "def rho_experiment(rho: float) -> List[List[Transition]]:\n",
    "    return parallelize(\n",
    "        n_proc=min(n_cpu, n_trials),\n",
    "        fn=run_io_rmpc(dataset_trajectories,\n",
    "                      dataset_length=300,\n",
    "                      n_past=n_past,\n",
    "                      add_bias=add_bias,\n",
    "                      expert_horizon=horizon,\n",
    "                      expert_rho=rho,\n",
    "                      plant=plant,\n",
    "                      dataset_permute_rng=np.random.default_rng(permute_seed)),\n",
    "        kwargs_list=[\n",
    "            dict(env_reset_rng=np.random.default_rng(_seed))\n",
    "            for _seed in trial_seeds\n",
    "        ],\n",
    "        loading_bar_kwargs=dict(desc=f\"MPC rho:{rho} trials\")\n",
    "    )\n",
    "\n",
    "\n",
    "rho_values = np.logspace(-2, -0.5, n_rhos)\n",
    "ablation_trajectories = parallelize(\n",
    "    n_proc=n_cpu // min(n_cpu, n_trials),\n",
    "    fn=rho_experiment,\n",
    "    kwargs_list=[\n",
    "        dict(rho=rho)\n",
    "        for rho in rho_values\n",
    "    ],\n",
    "    loading_bar_kwargs=dict(desc=\"IO-MPC rho ablation\")\n",
    ")\n",
    "\n",
    "# Save the experiment since it takes some time to complete.\n",
    "save_experiment(\n",
    "    values={\"rho_ablation\": {key: trajectories for key,\n",
    "                           trajectories in zip(rho_values, ablation_trajectories)}\n",
    "                           },\n",
    "    seed=general_seed,\n",
    "    exp_dir=\"./quadrotor_data/ablation\",\n",
    "    name=\"io_rmpc_rho\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io_agent.utils import steady_state_cost, load_experiment\n",
    "from io_agent.plotter import tube_figure\n",
    "\n",
    "exp_trajectories = load_experiment(\"./quadrotor_data/ablation/io_rmpc_rho-42\")\n",
    "io_rmpc_trajectories = exp_trajectories[\"rho_ablation\"]\n",
    "\n",
    "\n",
    "tube_figure(\n",
    "    cost_data={\n",
    "        \"IO-RMPC (25)\": {key: steady_state_cost(traj, 0.4)\n",
    "                        for key, traj in io_rmpc_trajectories.items()},\n",
    "    },\n",
    "    title=f\"rho ablation\",\n",
    "    log_xaxis=True,\n",
    "    log_yaxis=True,\n",
    "    xaxis_name=\"rho\",\n",
    "    percentiles=(20, 80)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CQL comparisons\n",
    "\n",
    "- Run CQL on MPC Quadrotor dataset with 4 seeds for 8 different dataset lengths\n",
    "- Evaluate CQL policies with 20 seeds for each epoch, data size, and training seed\n",
    "- Compare it with IO agent\n",
    "\n",
    "Run the following command to train a CQL controller. Note that, ```n_trajectories``` determines number of trajectories that is going to be used in the training. Each trajectory contains 300 steps.\n",
    "\n",
    "\n",
    "```bash\n",
    "python cql_quadrotor.py --n_trajectories 12 --device cuda:0 --seed 42\n",
    "```\n",
    "> **Note that:** The experiments require GPUs. In the paper, we evaluated each dataset size (different ```n_trajectories```) with 4 different seeds (42, 43, 44, 45).\n",
    "\n",
    "The trained agents will be used for evaluations.\n",
    "\n",
    "### Evaluation\n",
    "\n",
    "Run the cell below to evaluate the trained CQL agents. The evaluation process expects to have checkpoints under the checkpoints folder of each training.\n",
    "\n",
    "- Generate Trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_cql import generate_mpc_quadrotor_dataset\n",
    "\n",
    "\n",
    "generate_mpc_quadrotor_dataset(\n",
    "    horizon=25,\n",
    "    n_dataset_trials=100,\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Run cql trainings with 4 different seeds and with multiple trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import torch\n",
    "\n",
    "from run_cql import train_quadrotor_cql\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "for seed, n_trajectories in product([42, 43, 44, 45], [100, 80, 50, 25, 20, 15, 12, 10]):\n",
    "    train_quadrotor_cql(\n",
    "        n_trajectories=n_trajectories,\n",
    "        device=device,\n",
    "        seed=seed,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "from io_agent.utils import save_experiment\n",
    "from run_cql import evaluate_all_cql_quadrotor_policies\n",
    "\n",
    "\n",
    "cql_evaluations = evaluate_all_cql_quadrotor_policies(\n",
    "    experiment_path=\"./offlineRL_dataa/Quadrotor2d/cql\",\n",
    "    cql_seeds=[42, 43, 44, 45],\n",
    "    data_sizes=[100, 80, 50, 25, 20, 15, 12, 10],\n",
    "    epochs_numbers=list(range(1, 51)),\n",
    "    initial_seed=42,\n",
    "    n_trials=20,\n",
    "    n_proc=20,\n",
    ")\n",
    "save_experiment(\n",
    "    values={\"cql\": cql_evaluations},\n",
    "    seed=0,\n",
    "    exp_dir=\"./quadrotor_data/ablation\",\n",
    "    name=\"cql_epochs_and_dataset_length\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process and Accumulate the Evaluations Scores\n",
    "> Note: You need to run the above cells in order to generate the data\n",
    "- Convert rewards into costs\n",
    "- Get evaluations of IO and MPC agents from previous experiments\n",
    "- Get evaluation scores of the CQL and PPO agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "from io_agent.utils import load_experiment\n",
    "from io_agent.plotter import histogram_figure_plt, tube_figure_plt\n",
    "\n",
    "\n",
    "exp_trajectories = load_experiment(\"./quadrotor_data/ablation/io_mpc_lookbacks-42\")\n",
    "io_mpc_trajectories = exp_trajectories[\"h_ablation\"]\n",
    "\n",
    "exp_trajectories = load_experiment(\"./quadrotor_data/ablation/mpc_vs_ppo-42\")\n",
    "mpc_trajectories = exp_trajectories[\"mpc_ablation_trajectories\"]\n",
    "\n",
    "io_costs = [np.sum([1 - np.exp(-tran.cost) for tran in trajectory])\n",
    "            for trajectory in io_mpc_trajectories[0]]\n",
    "mpc_costs = [np.sum([1 - np.exp(-tran.cost) for tran in trajectory])\n",
    "             for trajectory in mpc_trajectories[(25, False)]]\n",
    "io_h_costs = {key: [[np.sum([1 - np.exp(-tran.cost) for tran in trajectory])]\n",
    "                    for trajectory in trajectories]\n",
    "              for key, trajectories in io_mpc_trajectories.items()}\n",
    "\n",
    "# - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "# - - - - - - - - - - - CQL - - - - - - - - - - -\n",
    "# - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "exp_trajectories = load_experiment(\"./quadrotor_data/ablation/cql_epochs_and_dataset_length-0\")\n",
    "cql_trajectories = exp_trajectories[\"cql\"]\n",
    "\n",
    "cql_datasize_eval = defaultdict(lambda: defaultdict(list))\n",
    "for data_size, seed_evals in cql_trajectories.items():\n",
    "    for seed_eval in seed_evals.values():\n",
    "        for index, scores in seed_eval.items():\n",
    "            cql_datasize_eval[data_size][index].extend([300 - s for s in scores])\n",
    "\n",
    "cql_datasize_eval_median = {data_size: {key: np.median(evals) for key, evals in epoch_eval.items()}\n",
    "                            for data_size, epoch_eval in cql_datasize_eval.items()}\n",
    "best_indices = {data_size: min(median_eval.items(), key=lambda key: key[1])[0]\n",
    "                for data_size, median_eval in cql_datasize_eval_median.items()}\n",
    "\n",
    "exp_trajectories = load_experiment(\"./quadrotor_data/ablation/io_rmpc_rho-42\")\n",
    "io_rmpc_trajectories = exp_trajectories[\"rho_ablation\"]\n",
    "\n",
    "io_rho_costs = {rho: [np.sum([1 - np.exp(-tran.cost) for tran in trajectory]) for trajectory in trajectories]\n",
    "                for rho, trajectories in io_rmpc_trajectories.items()}\n",
    "best_io_rmpc_rho, best_io_rmpc_cost = min(io_rho_costs.items(), key=lambda key: np.median(key[1]))\n",
    "\n",
    "# - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "# - - - - - - - - - - - PPO - - - - - - - - - - -\n",
    "# - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "exp_trajectories = load_experiment(\"./quadrotor_data/ablation/mpc_vs_ppo-42\")\n",
    "ppo_trajectories = exp_trajectories[\"ppo_trajectories\"]\n",
    "\n",
    "ppo_costs = [np.sum([1 - np.exp(-tran.cost) for tran in trajectory])\n",
    "             for trajectory in ppo_trajectories]\n",
    "\n",
    "\n",
    "# - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "# - - - - - - - - - - - MPC vs PPO - - - - - - -\n",
    "# - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "mpc_horizon_keys = [horizon for horizon, awareness in mpc_trajectories.keys()]\n",
    "mpc_obl_costs = {key: [np.sum([1 - np.exp(-tran.cost) for tran in trajectory])\n",
    "                       for trajectory in mpc_trajectories[(key, False)]]\n",
    "                 for key in mpc_horizon_keys}\n",
    "mpc_fdst_costs = {key: [np.sum([1 - np.exp(-tran.cost) for tran in trajectory])\n",
    "                        for trajectory in mpc_trajectories[(key, True)]]\n",
    "                  for key in mpc_horizon_keys}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Figures in the paper\n",
    "\n",
    "- Lookback Ablation of IO-MPC controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io_h_ss_costs = {key: [[30/18 * np.sum([1 - np.exp(-tran.cost) for tran in trajectory[120:]])]\n",
    "                       for trajectory in trajectories]\n",
    "                 for key, trajectories in io_mpc_trajectories.items()}\n",
    "mpc_obl_ss_costs = [30/18 * np.sum([1 - np.exp(-tran.cost) for tran in trajectory[120:]])\n",
    "                    for trajectory in mpc_trajectories[(25, False)]]\n",
    "mpc_fdst_ss_costs = [30/18 * np.sum([1 - np.exp(-tran.cost) for tran in trajectory[120:]])\n",
    "                     for trajectory in mpc_trajectories[(25, True)]]\n",
    "\n",
    "fig, axes = tube_figure_plt(\n",
    "    cost_data={\n",
    "        \"IO-MPC (N=25)\": io_h_ss_costs,\n",
    "        \"MPC (obl, N=25)\": {key: mpc_obl_ss_costs\n",
    "                            for key in io_h_costs.keys()},\n",
    "        \"MPC (f-dst, N=25)\": {key: mpc_fdst_ss_costs\n",
    "                              for key in io_h_costs.keys()},\n",
    "    },\n",
    "    title=f\"\",\n",
    "    log_xaxis=False,\n",
    "    log_yaxis=True,\n",
    "    x_label=\"lookback horizon H\",\n",
    "    y_label=\"ss episodic cost\",\n",
    "    percentiles=(45, 55)\n",
    ")\n",
    "fig.savefig(f\"figure_data/io_lookback_ablation.svg\", format=\"svg\", dpi=1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Horizon Ablation of MPC controllers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = tube_figure_plt(\n",
    "    cost_data={\n",
    "        \"MPC (f-dst)\": mpc_fdst_costs,\n",
    "        \"MPC (obl)\": mpc_obl_costs,\n",
    "        \"PPO-3M\": {key: ppo_costs for key in mpc_obl_costs.keys()}\n",
    "    },\n",
    "    title=f\"\",\n",
    "    log_xaxis=False,\n",
    "    log_yaxis=True,\n",
    "    x_label=\"MPC horizon N\",\n",
    "    y_label=\"episodic cost\",\n",
    "    percentiles=(20, 80)\n",
    ")\n",
    "fig.savefig(f\"figure_data/mpc_horizon_ablation.svg\", format=\"svg\", dpi=1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\rho$ Ablation of IO-RMPC controllers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = tube_figure_plt(\n",
    "    cost_data={\n",
    "        \"IO-RMPC (N=25)\": io_rho_costs,\n",
    "        \"IO-MPC (N=25)\": {rho: io_costs for rho in io_rho_costs.keys()},\n",
    "    },\n",
    "    title=f\"\",\n",
    "    log_xaxis=True,\n",
    "    log_yaxis=True,\n",
    "    x_label=\"Uncertainty radius $\\\\rho$\",\n",
    "    y_label=\"episodic cost\",\n",
    "    percentiles=(40, 60)\n",
    ")\n",
    "fig.savefig(f\"figure_data/rho_ablation.svg\", format=\"svg\", dpi=1200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Dataset size ablation of CQL controllers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = tube_figure_plt(\n",
    "    cost_data={\n",
    "        f\"CQL\": {data_size * 300: epoch_evals[best_indices[data_size]]\n",
    "                 for data_size, epoch_evals in cql_datasize_eval.items()},\n",
    "        \"IO-RMPC* (T=3000)\": {data_size * 300: io_rho_costs[best_io_rmpc_rho]\n",
    "                    for data_size in cql_datasize_eval.keys()}\n",
    "    },\n",
    "    title=f\"\",\n",
    "    log_xaxis=True,\n",
    "    log_yaxis=False,\n",
    "    x_label=\"dataset size T\",\n",
    "    y_label=\"episodic cost\",\n",
    "    percentiles=(20, 80)\n",
    ")\n",
    "axes.xaxis.set_major_formatter(matplotlib.ticker.ScalarFormatter())\n",
    "axes.set_xticks([3000, 5000, 10000, 20000, 30000])\n",
    "fig.savefig(f\"figure_data/dataset_ablation.svg\", format=\"svg\", dpi=1200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comparison between IO and MPC controllers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = histogram_figure_plt(\n",
    "    cost_data={\n",
    "        \"IO-RMPC* (T=3000)\": io_rho_costs[best_io_rmpc_rho],\n",
    "        \"IO-MPC (T=3000)\": io_costs,\n",
    "        \"MPC (obl)\": mpc_costs,\n",
    "        \"MPC (fdst)\": mpc_fdst_costs[25],\n",
    "    },\n",
    "    title=\"\",\n",
    "    bw_method=\"scott\",\n",
    "    bw_adjust=0.30,\n",
    "    log_yaxis=True,\n",
    "    y_label=\"log density\",\n",
    "    low_y=1e-3,\n",
    "    figsize=(6, 3)\n",
    ")\n",
    "fig.savefig(f\"figure_data/hist_2.svg\", format=\"svg\", dpi=1200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comparison between offline IO, CQL, and online PPO controllers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = histogram_figure_plt(\n",
    "    cost_data={\n",
    "        f\"CQL (T=30000)\": cql_datasize_eval[100][best_indices[100]],\n",
    "        f\"CQL (T=3000) \": cql_datasize_eval[10][best_indices[10]],\n",
    "        \"IO-RMPC* (T=3000)\": io_rho_costs[best_io_rmpc_rho],\n",
    "        f\"PPO-3M\": ppo_costs,\n",
    "    },\n",
    "    title=\"\",\n",
    "    bw_method=\"scott\",\n",
    "    bw_adjust=0.30,\n",
    "    log_yaxis=True,\n",
    "    y_label=\"log density\",\n",
    "    low_y=1e-3,\n",
    "    figsize=(6, 3),\n",
    "    use_grid=False\n",
    ")\n",
    "fig.savefig(f\"figure_data/hist_1.svg\", format=\"svg\", dpi=1200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
